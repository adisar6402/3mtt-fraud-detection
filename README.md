# ğŸ›¡ï¸ 3MTT Fraud Detection AI/ML Project

This mini-project simulates a real-world fraud detection system using a trained logistic regression model. The system is deployed via a FastAPI REST API, containerized using Docker, and demonstrates simulated real-time data streaming to emulate message queue behavior (like Kafka).

---

## ğŸ“Œ Project Overview

- âœ… **Model**: Logistic Regression for binary classification (Fraudulent or Legit)  
- âš™ï¸ **API**: FastAPI-based prediction endpoint  
- ğŸ“¦ **Containerization**: Docker-ready with simple build/run  
- ğŸ”„ **Streaming**: Simulated real-time streaming using Python queue  
- ğŸ“ **Platform**: Built and tested in Google Colab  

---

## ğŸ§  Model Training

The model was trained on a synthetic dataset of transactions with features:

- `age`
- `salary`
- `transaction_amount`

It was scaled using `StandardScaler`, trained using `LogisticRegression`, and both artifacts (`fraud_model.pkl` and `scaler.pkl`) were saved for deployment.

---

## ğŸš€ FastAPI Endpoint

The API receives POST requests with transaction data and responds with a fraud prediction.

### ğŸ§ª Sample Input
```json
{
  "age": 45,
  "salary": 50000,
  "transaction_amount": 3000
}
```

### âœ… Sample Response
```json
{
  "prediction": "Fraudulent"
}
```

---

## ğŸ³ Docker Containerization

To make the FastAPI app portable and deployment-ready, we containerized it using Docker.

### ğŸ“„ Dockerfile
```Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY fraud_api.py .
COPY fraud_model.pkl .
COPY scaler.pkl .

EXPOSE 8000

CMD ["uvicorn", "fraud_api:app", "--host", "0.0.0.0", "--port", "8000"]
```

### ğŸ“ Project Structure
```
project/
â”‚
â”œâ”€â”€ fraud_api.py               # FastAPI prediction API  
â”œâ”€â”€ fraud_model.pkl            # Trained logistic regression model  
â”œâ”€â”€ scaler.pkl                 # Feature scaler  
â”œâ”€â”€ requirements.txt           # App dependencies  
â””â”€â”€ Dockerfile                 # Docker build instructions  
```

---

## ğŸ”„ Real-Time Streaming Simulation

We simulated Kafka-like streaming using a Python loop and queue.

```python
import time, pandas as pd, joblib

model = joblib.load("fraud_model.pkl")
scaler = joblib.load("scaler.pkl")

transaction_stream = [
    {"age": 25, "salary": 30000, "transaction_amount": 800},
    {"age": 45, "salary": 50000, "transaction_amount": 3000},
    {"age": 38, "salary": 45000, "transaction_amount": 1500},
    {"age": 52, "salary": 70000, "transaction_amount": 5200},
]

print("ğŸš€ Simulating real-time transaction stream...\n")
for txn in transaction_stream:
    input_df = pd.DataFrame([txn])
    input_scaled = scaler.transform(input_df)
    prediction = model.predict(input_scaled)[0]
    result = "Fraudulent" if prediction == 1 else "Legit"
    print(f"â¡ï¸ {txn} â†’ ğŸ§  Prediction: {result}")
    time.sleep(0.5)

print("\nâœ… Streaming simulation complete.")
```

---

## âš¡ Running with Ngrok (Google Colab)

To expose the FastAPI app in Google Colab:
```python
!pip install fastapi uvicorn nest-asyncio pyngrok -q

import nest_asyncio
from pyngrok import ngrok
import uvicorn

nest_asyncio.apply()
ngrok.set_auth_token("your_ngrok_token_here")
public_url = ngrok.connect(8000)
print(f"ğŸ”— Public FastAPI URL: {public_url}")

uvicorn.run("fraud_api:app", host="0.0.0.0", port=8000)
```

---

## ğŸ› ï¸ How to Run Locally with Docker

1. ğŸ”§ Build the image:
```bash
docker build -t fraud-api .
```

2. ğŸš€ Run the container:
```bash
docker run -p 8000:8000 fraud-api
```

3. ğŸŒ Access the API:
```
http://localhost:8000/docs
```

---

## ğŸ“¬ Author

**Abdulrahman Adisa Amuda**  
IBM Certified | AI/ML Enthusiast | 3MTT Trainee  
ğŸ”— [GitHub Profile](https://github.com/adisar6402)

---

## âœ… Status

ğŸ“ Project Complete & Ready for Evaluation  
ğŸ“¦ Fully Dockerized  
ğŸ§  Machine Learning Integrated  
âš™ï¸ FastAPI Operational  
ğŸ”„ Streaming Logic Simulated  

---

## ğŸ“¢ License

This project is licensed for educational purposes under the MIT License.
